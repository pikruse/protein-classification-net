{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we train a Deep Learning model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sys, os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "# make a toy dataset with 1000 samples\n",
    "np.random.seed(0)\n",
    "n = 1000 # number of samples\n",
    "x = np.random.rand(n, 1)\n",
    "y = 2 * x + 1 + (0.1 * np.random.randn(n, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    "`x -> model -> y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the data into a torch tensor\n",
    "x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple dataset class\n",
    "class SimpleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "    \n",
    "    # what happens when we call len(dataset)?\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    # what happens when we call dataset[idx]?\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "\n",
    "dataset = SimpleDataset(x_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataloader and split into train and test\n",
    "train_prop = 0.8 # 80%\n",
    "train_size = int(train_prop * len(dataset)) # .80 * 1000 = 800\n",
    "train_idx = np.random.choice(len(dataset), train_size, replace=False) # random sample 800 indices, w/o replacement\n",
    "test_idx = np.setdiff1d(np.arange(len(dataset)), train_idx) # get the indices that are not in train_idx\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx) \n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1]) torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in train_loader:\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the model\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # architecture: fc (1 -> 64) -> ReLU -> fc (64 -> 1)\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc1(x) # 1 -> 64\n",
    "        x = self.act(x) # 64\n",
    "        x = self.fc2(x) # 64 -> 1\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1587750911712646\n"
     ]
    }
   ],
   "source": [
    "# single example\n",
    "# get batch\n",
    "x, y = next(iter(train_loader))\n",
    "\n",
    "# zero the gradients (tell the optimizer to forget the gradients from the last batch)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# forward pass (make a prediction)\n",
    "y_pred = model(x)\n",
    "\n",
    "# calculate the loss\n",
    "loss = loss_fn(y_pred, y)\n",
    "print(loss.item())\n",
    "\n",
    "# backward pass (calculate the gradients)\n",
    "loss.backward()\n",
    "\n",
    "# update the weights\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.073629379272461 | Batch: 100/100\r"
     ]
    }
   ],
   "source": [
    "# training loop (single epoch)\n",
    "\n",
    "i = 0\n",
    "# get batch\n",
    "for x, y in train_loader:\n",
    "    \n",
    "    # zero the gradients (tell the optimizer to forget the gradients from the last batch)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass (make a prediction)\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # calculate the loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    # backward pass (calculate the gradients)\n",
    "    loss.backward()\n",
    "\n",
    "    # update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    print(f\"Loss: {loss.item()} | Batch: {i}/{len(train_loader)}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure training, set up the optimizer\n",
    "model = Net()\n",
    "loss_fn = nn.MSELoss() # loss function: what direction we want to go\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3) # learning rate: how much we want to move in that direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 | Train Loss: 1.0350 | Test Loss: 0.1132\n",
      "Epoch: 2/100 | Train Loss: 0.0629 | Test Loss: 0.0280\n",
      "Epoch: 3/100 | Train Loss: 0.0187 | Test Loss: 0.0129\n",
      "Epoch: 4/100 | Train Loss: 0.0124 | Test Loss: 0.0109\n",
      "Epoch: 5/100 | Train Loss: 0.0111 | Test Loss: 0.0098\n",
      "Epoch: 6/100 | Train Loss: 0.0104 | Test Loss: 0.0094\n",
      "Epoch: 7/100 | Train Loss: 0.0100 | Test Loss: 0.0093\n",
      "Epoch: 8/100 | Train Loss: 0.0097 | Test Loss: 0.0091\n",
      "Epoch: 9/100 | Train Loss: 0.0097 | Test Loss: 0.0100\n",
      "Epoch: 10/100 | Train Loss: 0.0096 | Test Loss: 0.0095\n",
      "Epoch: 11/100 | Train Loss: 0.0094 | Test Loss: 0.0092\n",
      "Epoch: 12/100 | Train Loss: 0.0096 | Test Loss: 0.0095\n",
      "Epoch: 13/100 | Train Loss: 0.0094 | Test Loss: 0.0094\n",
      "Epoch: 14/100 | Train Loss: 0.0095 | Test Loss: 0.0092\n",
      "Epoch: 15/100 | Train Loss: 0.0095 | Test Loss: 0.0093\n",
      "Epoch: 16/100 | Train Loss: 0.0094 | Test Loss: 0.0094\n",
      "Epoch: 17/100 | Train Loss: 0.0094 | Test Loss: 0.0093\n",
      "Epoch: 18/100 | Train Loss: 0.0094 | Test Loss: 0.0093\n",
      "Epoch: 19/100 | Train Loss: 0.0095 | Test Loss: 0.0095\n",
      "Epoch: 20/100 | Train Loss: 0.0096 | Test Loss: 0.0093\n",
      "Epoch: 21/100 | Train Loss: 0.0095 | Test Loss: 0.0092\n",
      "Epoch: 22/100 | Train Loss: 0.0096 | Test Loss: 0.0096\n",
      "Epoch: 23/100 | Train Loss: 0.0094 | Test Loss: 0.0093\n",
      "Epoch: 24/100 | Train Loss: 0.0096 | Test Loss: 0.0095\n",
      "Epoch: 25/100 | Train Loss: 0.0096 | Test Loss: 0.0092\n",
      "Epoch: 26/100 | Train Loss: 0.0094 | Test Loss: 0.0098\n",
      "Epoch: 27/100 | Train Loss: 0.0094 | Test Loss: 0.0096\n",
      "Epoch: 28/100 | Train Loss: 0.0098 | Test Loss: 0.0094\n",
      "Epoch: 29/100 | Train Loss: 0.0097 | Test Loss: 0.0092\n",
      "Epoch: 30/100 | Train Loss: 0.0097 | Test Loss: 0.0112\n",
      "Epoch: 31/100 | Train Loss: 0.0098 | Test Loss: 0.0102\n",
      "Epoch: 32/100 | Train Loss: 0.0095 | Test Loss: 0.0096\n",
      "Epoch: 33/100 | Train Loss: 0.0097 | Test Loss: 0.0095\n",
      "Epoch: 34/100 | Train Loss: 0.0095 | Test Loss: 0.0100\n",
      "Epoch: 35/100 | Train Loss: 0.0096 | Test Loss: 0.0093\n",
      "Epoch: 36/100 | Train Loss: 0.0095 | Test Loss: 0.0093\n",
      "Epoch: 37/100 | Train Loss: 0.0097 | Test Loss: 0.0092\n",
      "Epoch: 38/100 | Train Loss: 0.0097 | Test Loss: 0.0096\n",
      "Epoch: 39/100 | Train Loss: 0.0096 | Test Loss: 0.0093\n",
      "Epoch: 40/100 | Train Loss: 0.0098 | Test Loss: 0.0111\n",
      "Epoch: 41/100 | Train Loss: 0.0099 | Test Loss: 0.0099\n",
      "Epoch: 42/100 | Train Loss: 0.0097 | Test Loss: 0.0095\n",
      "Epoch: 43/100 | Train Loss: 0.0099 | Test Loss: 0.0093\n",
      "Epoch: 44/100 | Train Loss: 0.0098 | Test Loss: 0.0093\n",
      "Epoch: 45/100 | Train Loss: 0.0097 | Test Loss: 0.0095\n",
      "Epoch: 46/100 | Train Loss: 0.0097 | Test Loss: 0.0094\n",
      "Epoch: 47/100 | Train Loss: 0.0098 | Test Loss: 0.0093\n",
      "Epoch: 48/100 | Train Loss: 0.0096 | Test Loss: 0.0095\n",
      "Epoch: 49/100 | Train Loss: 0.0096 | Test Loss: 0.0095\n",
      "Epoch: 50/100 | Train Loss: 0.0097 | Test Loss: 0.0096\n",
      "Epoch: 51/100 | Train Loss: 0.0099 | Test Loss: 0.0101\n",
      "Epoch: 52/100 | Train Loss: 0.0096 | Test Loss: 0.0092\n",
      "Epoch: 53/100 | Train Loss: 0.0094 | Test Loss: 0.0097\n",
      "Epoch: 54/100 | Train Loss: 0.0098 | Test Loss: 0.0093\n",
      "Epoch: 55/100 | Train Loss: 0.0096 | Test Loss: 0.0092\n",
      "Epoch: 56/100 | Train Loss: 0.0097 | Test Loss: 0.0094\n",
      "Epoch: 57/100 | Train Loss: 0.0095 | Test Loss: 0.0093\n",
      "Epoch: 58/100 | Train Loss: 0.0095 | Test Loss: 0.0116\n",
      "Epoch: 59/100 | Train Loss: 0.0097 | Test Loss: 0.0094\n",
      "Epoch: 60/100 | Train Loss: 0.0096 | Test Loss: 0.0098\n",
      "Epoch: 61/100 | Train Loss: 0.0096 | Test Loss: 0.0092\n",
      "Epoch: 62/100 | Train Loss: 0.0098 | Test Loss: 0.0099\n",
      "Epoch: 63/100 | Train Loss: 0.0099 | Test Loss: 0.0092\n",
      "Epoch: 64/100 | Train Loss: 0.0097 | Test Loss: 0.0095\n",
      "Epoch: 65/100 | Train Loss: 0.0096 | Test Loss: 0.0102\n",
      "Epoch: 66/100 | Train Loss: 0.0100 | Test Loss: 0.0096\n",
      "Epoch: 67/100 | Train Loss: 0.0098 | Test Loss: 0.0096\n",
      "Epoch: 68/100 | Train Loss: 0.0096 | Test Loss: 0.0098\n",
      "Epoch: 69/100 | Train Loss: 0.0096 | Test Loss: 0.0094\n",
      "Epoch: 70/100 | Train Loss: 0.0096 | Test Loss: 0.0096\n",
      "Epoch: 71/100 | Train Loss: 0.0098 | Test Loss: 0.0094\n",
      "Epoch: 72/100 | Train Loss: 0.0095 | Test Loss: 0.0103\n",
      "Epoch: 73/100 | Train Loss: 0.0097 | Test Loss: 0.0095\n",
      "Epoch: 74/100 | Train Loss: 0.0096 | Test Loss: 0.0092\n",
      "Epoch: 75/100 | Train Loss: 0.0095 | Test Loss: 0.0093\n",
      "Epoch: 76/100 | Train Loss: 0.0096 | Test Loss: 0.0092\n",
      "Epoch: 77/100 | Train Loss: 0.0098 | Test Loss: 0.0106\n",
      "Epoch: 78/100 | Train Loss: 0.0099 | Test Loss: 0.0092\n",
      "Epoch: 79/100 | Train Loss: 0.0098 | Test Loss: 0.0100\n",
      "Epoch: 80/100 | Train Loss: 0.0099 | Test Loss: 0.0094\n",
      "Epoch: 81/100 | Train Loss: 0.0100 | Test Loss: 0.0093\n",
      "Epoch: 82/100 | Train Loss: 0.0096 | Test Loss: 0.0094\n",
      "Epoch: 83/100 | Train Loss: 0.0097 | Test Loss: 0.0096\n",
      "Epoch: 84/100 | Train Loss: 0.0095 | Test Loss: 0.0092\n",
      "Epoch: 85/100 | Train Loss: 0.0097 | Test Loss: 0.0093\n",
      "Epoch: 86/100 | Train Loss: 0.0095 | Test Loss: 0.0092\n",
      "Epoch: 87/100 | Train Loss: 0.0096 | Test Loss: 0.0100\n",
      "Epoch: 88/100 | Train Loss: 0.0097 | Test Loss: 0.0098\n",
      "Epoch: 89/100 | Train Loss: 0.0096 | Test Loss: 0.0092\n",
      "Epoch: 90/100 | Train Loss: 0.0097 | Test Loss: 0.0092\n",
      "Epoch: 91/100 | Train Loss: 0.0100 | Test Loss: 0.0099\n",
      "Epoch: 92/100 | Train Loss: 0.0101 | Test Loss: 0.0094\n",
      "Epoch: 93/100 | Train Loss: 0.0100 | Test Loss: 0.0093\n",
      "Epoch: 94/100 | Train Loss: 0.0099 | Test Loss: 0.0092\n",
      "Epoch: 95/100 | Train Loss: 0.0097 | Test Loss: 0.0095\n",
      "Epoch: 96/100 | Train Loss: 0.0098 | Test Loss: 0.0093\n",
      "Epoch: 97/100 | Train Loss: 0.0094 | Test Loss: 0.0092\n",
      "Epoch: 98/100 | Train Loss: 0.0095 | Test Loss: 0.0094\n",
      "Epoch: 99/100 | Train Loss: 0.0100 | Test Loss: 0.0106\n",
      "Epoch: 100/100 | Train Loss: 0.0096 | Test Loss: 0.0096\n"
     ]
    }
   ],
   "source": [
    "# training loop (multiple epochs)\n",
    "n_epochs = 100\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # init losses\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "\n",
    "    # get batch\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        # zero the gradients (tell the optimizer to forget the gradients from the last batch)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass (make a prediction)\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # backward pass (calculate the gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    # normalize the loss\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "\n",
    "            # forward pass (make a prediction)\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # calculate the loss\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_losses.append(loss.item())\n",
    "    \n",
    "    # normalize the loss\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{n_epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the losses per epoch\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
